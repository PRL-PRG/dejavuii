---
title: "Folder Clone Histories Analysis"
output: html_notebook
---

> NOTE: This is a work in progress. The code is ugly, the comments are rough and so on. 

Define some helper functions and data root directory. 

> These should be refactored to a special file when I have time.

```{r}
# better CSV reader
library(readr)
library(dplyr)
library(ggplot2)

DROOT = "/data/dejavuii/full"
dFilePath <- function(x) {
    paste0(DROOT,"/",x)
}
dRead <- function (x) {
    read_delim(dFilePath(x), delim=',', escape_double=FALSE, escape_backslash=TRUE, quote="\"")
}
dLog <- function(msg, data, pct = NULL) {
    if (! is.null(pct)) {
        cat(paste0(msg, ": ", data, " (",round((data / pct) * 100, digits = 2), "%)\n"))
    } else {
        cat(paste0(msg, ": ", data, "\n"))
    }
}
```

## Data Import

First load the projects info so that we can reference them easily. One large table is created which contains clone summaries for all projects.

```{r}
d = dRead("projectFolderCloneSummary.csv")
p = dRead("projects.csv")
p$url = paste0("http://github.com/", p$user, "/", p$repo)
npm = dRead("npmModulesCounts.csv")
projects = merge(d, p, by.x = "#projectId", by.y = "#id")
projects = merge(projects, npm, by.x = "#projectId", by.y = "#projectId")
# clean the data we don't need
remove(d)
remove(p)
remove(npm)
```

Then load the clone originals information:

```{r}
co = dRead("folderCloneOriginals.csv")
cw = dRead("folderClonesWeights.csv")
cOriginals = merge(co, cw, by.x = "#id", by.y="#cloneId")
remove(co)
remove(cw)
```

Finally load the summary of changes to the clones.

```{r}
clones = dRead("folderClonesHistorySummary.csv")
```

Finally, make the column names nicer, i.e. drop the leading '#'

```{r}
colnames(projects)[[1]] = "projectIdd"
colnames(cOriginals)[[1]] = "cloneId"
colnames(clones)[[1]] = "projectId"
```

Summary:

```{r}
dLog("Number of projects", nrow(projects))
dLog("Number of clone originals", nrow(cOriginals))
dLog("Number of clone occurences", nrow(clones))
```


    Place := (project, path, commit)


- create graph that aggregates time + # of files cloned and files originals (look over commit times)

## Summaries

First thing to ask is how many of the clone occurences are never changed:

```{r}
neverChanged = clones[clones$changes + clones$merges + clones$deletions == 0,]
dLog("Number of clone occurences that are never touched", nrow(neverChanged), pct = nrow(clones))
neverChanged = clones[clones$changes + clones$merges == 0,]
dLog("Number of clone occurences that never changed", nrow(neverChanged), pct = nrow(clones))
```

The changes are total changes. What we perhaps want to see is how much of the clone actually gets changed:

```{r}
pctChange = clones$changedFiles / clones$files
summary(pctChange)
hist(pctChange)
```

```{r}
pctDel = clones$deletedFiles / clones$deletions
summary(pctDel)
hist(pctDel)
```

```{r}
summary(clones$files)
```

Another thing is how many changes are there per file, which is also reasonably easy to get:

```{r}
changedClones = clones[clones$changes > 0,]
x = changedClones$changes / changedClones$files
summary(x)
hist(log10(x), breaks = 100)
```

This is interesting - it seems that we peak around 0 (remember the log scale, i.e. this means that most frequent is an average of 1 change per file), 100 changes per file are not too uncommon either. 

We must take this with a grain of salt though as we average total number of changes to *all* files divided by number of files. It does not say that for most clones each file is changed once, just that most often the cummulative number of changes is similar to the number of files. 

> Creating a data to actually analyze this does not sound like totally dumb idea:)

Another thing to do is to see how often certain path is "re-cloned", i.e. how often we observe a clone in same project and same path:

```{r}
x = clones %>% group_by(projectId,path) %>% summarize(count = n())
```

```{r}
summary(x$count)
h <- hist(x$count, plot=F, breaks = 100) 
plot(log10(h$counts), pch=20, col="blue", xlab = "# of clones in same project/path pair", ylab="Frequency (log10)", type = "h")
```

So by two orders of magnitude the most is one clone per path / project. However, the other # of clones are not unheard of and the extremes are pretty extreme. 

> If there are multiple project/path clones, do they all originate in same project?

```{r}
x = clones %>% select(projectId, path, files, cloneId) %>% inner_join(cOriginals, by = c("cloneId", "cloneId")) %>% select(-weight, -weightProjects, -weightRoots)
```


```{r}
notFull = x[x$files < x$numFiles,]
```

> This is unexpected, all the clones are full clones... There seems to be sth off? 


### Relation with NPMs

How to plot this? 

# Stuffz

```{r}
x = cOriginals %>% filter(weight > 1)
```



```{r}
overtime = dRead("../test/clones_over_time.csv")
colnames(overtime)[[1]] = "time"
pd = overtime %>% filter(time > 1199145600)

```

```{r}
#x = overtime %>% select(-c("#time"))
# plot
ggplot(data = pd, aes(x=time)) +
  geom_line(aes(y = files, colour = "files")) + 
  geom_line(aes(y = npmFiles, colour = "npm files")) +
  geom_line(aes(y = clones, colour = "clones")) + 
  geom_line(aes(y = npmClones, colour = "npm clones")) +
  geom_line(aes(y = folderClones, colour = "folder clones")) + 
  geom_line(aes(y = npmFolderClones, colour = "npm folder clones")) + 
  geom_line(aes(y = folderClones, colour = "changed folder clones")) + 
  geom_line(aes(y = npmFolderClones, colour = "npm changed folder clones"))    
 
```





